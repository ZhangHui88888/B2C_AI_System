# 10.2 监控维护

本文档详细说明 DTC 独立站系统的监控和维护方案。

## 目录

1. [日志系统](#日志系统)
2. [性能监控](#性能监控)
3. [备份策略](#备份策略)
4. [告警配置](#告警配置)
5. [故障排查](#故障排查)

---

## 日志系统

### 结构化日志

系统使用 JSON 格式的结构化日志，便于查询和分析：

```json
{
  "timestamp": "2024-12-25T10:30:00.000Z",
  "level": "info",
  "message": "Request completed",
  "context": {
    "requestId": "abc123",
    "brandId": "brand-uuid",
    "path": "/api/products",
    "method": "GET"
  },
  "duration": 45,
  "metadata": {
    "status": 200,
    "rowCount": 10
  }
}
```

### 日志级别

| 级别 | 用途 | 环境 |
|------|------|------|
| `debug` | 详细调试信息 | 仅开发环境 |
| `info` | 常规操作日志 | 所有环境 |
| `warn` | 警告信息（非致命） | 所有环境 |
| `error` | 错误信息 | 所有环境 |

### 查看日志

**通过 Wrangler CLI：**

```bash
# 实时查看日志
wrangler tail

# 查看生产环境日志
wrangler tail --env production

# 过滤特定请求
wrangler tail --env production --format json | jq 'select(.level == "error")'
```

**通过 Cloudflare Dashboard：**

1. 进入 Workers & Pages
2. 选择 Worker
3. 点击 "Logs" 标签
4. 实时查看或使用过滤器

### 日志保留策略

| 环境 | 保留时间 | 备注 |
|------|----------|------|
| 开发 | 24 小时 | Cloudflare 默认 |
| 生产 | 7 天 | Cloudflare 默认 |
| 归档 | 90 天 | 需配置外部存储 |

### 外部日志存储（可选）

如需长期存储日志，可配置 Logpush：

```bash
# 配置 Logpush 到 R2
wrangler logpush create \
  --dataset=workers_trace_events \
  --destination-conf="r2://<bucket>/<prefix>?account-id=<account-id>" \
  --env production
```

---

## 性能监控

### 内置监控端点

| 端点 | 说明 |
|------|------|
| `GET /api/health` | 简单健康检查 |
| `GET /api/health/detailed` | 详细健康检查（含依赖状态） |
| `GET /api/ready` | 就绪检查（负载均衡用） |
| `GET /api/live` | 存活检查 |
| `GET /api/metrics` | 性能指标 |
| `GET /api/metrics/endpoints` | 按端点统计 |
| `GET /api/metrics/prometheus` | Prometheus 格式指标 |
| `GET /api/system` | 系统信息 |

### 指标说明

**请求指标：**
- `totalRequests`: 总请求数
- `successfulRequests`: 成功请求数（2xx/3xx）
- `failedRequests`: 失败请求数（4xx/5xx）
- `averageLatency`: 平均响应时间
- `p95Latency`: 95 百分位延迟
- `p99Latency`: 99 百分位延迟

**状态码分布：**
```json
{
  "statusCodes": {
    "200": 1500,
    "201": 50,
    "400": 10,
    "404": 5,
    "500": 2
  }
}
```

### Cloudflare Analytics

通过 Dashboard 查看更详细的分析：

1. Workers & Pages → 选择 Worker
2. "Analytics" 标签
3. 可查看：
   - 请求量趋势
   - CPU 时间
   - 错误率
   - 地理分布

### 自定义监控集成

**Prometheus 集成：**

```yaml
# prometheus.yml
scrape_configs:
  - job_name: 'dtc-api'
    scrape_interval: 30s
    static_configs:
      - targets: ['api.yourdomain.com']
    metrics_path: '/api/metrics/prometheus'
```

**Grafana Dashboard：**

导入以下查询创建仪表盘：

```promql
# 请求率
rate(http_requests_total[5m])

# 错误率
rate(http_requests_failed_total[5m]) / rate(http_requests_total[5m])

# 延迟
http_request_duration_milliseconds{quantile="0.95"}
```

---

## 备份策略

### Supabase 数据库备份

**自动备份（Supabase Pro 及以上）：**
- 每日自动备份
- 保留 7 天（Pro）/ 30 天（Team）
- 点对点恢复（PITR）

**手动备份：**

```bash
# 使用 pg_dump 导出
pg_dump "postgresql://postgres:[password]@db.[project].supabase.co:5432/postgres" \
  -F c -b -v -f backup_$(date +%Y%m%d).dump

# 导出特定表
pg_dump "postgresql://..." -t products -t orders -F c -f partial_backup.dump
```

**定时备份脚本：**

```bash
#!/bin/bash
# scripts/backup-database.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="./backups"
RETENTION_DAYS=30

# 创建备份
pg_dump "$DATABASE_URL" -F c -b -v -f "$BACKUP_DIR/backup_$DATE.dump"

# 压缩
gzip "$BACKUP_DIR/backup_$DATE.dump"

# 上传到 R2/S3
aws s3 cp "$BACKUP_DIR/backup_$DATE.dump.gz" \
  "s3://your-backup-bucket/db/$DATE.dump.gz" \
  --endpoint-url "$R2_ENDPOINT"

# 清理旧备份
find "$BACKUP_DIR" -name "*.dump.gz" -mtime +$RETENTION_DAYS -delete
```

### KV 数据备份

KV 数据通常是缓存，不需要备份。如有重要数据：

```bash
# 导出 KV 数据
wrangler kv:key list --namespace-id=<namespace-id> | \
  jq -r '.[].name' | \
  while read key; do
    wrangler kv:key get --namespace-id=<namespace-id> "$key" > "kv_backup/$key"
  done
```

### 代码和配置备份

代码通过 Git 管理，确保：

- [ ] 主分支受保护
- [ ] 启用 GitHub 备份（Settings → Options → Backup）
- [ ] 敏感配置不提交到 Git（使用 secrets）

### 恢复流程

**数据库恢复：**

```bash
# 从 Supabase Dashboard 恢复（推荐）
# Dashboard → Database → Backups → Restore

# 手动恢复
pg_restore -d "$DATABASE_URL" -c -v backup.dump
```

**KV 恢复：**

```bash
# 批量写入
for file in kv_backup/*; do
  key=$(basename "$file")
  wrangler kv:key put --namespace-id=<namespace-id> "$key" --path="$file"
done
```

### 备份检查清单

| 项目 | 频率 | 保留期 | 存储位置 |
|------|------|--------|----------|
| 数据库完整备份 | 每日 | 30 天 | Supabase + R2 |
| 数据库增量备份 | 每小时 | 7 天 | Supabase PITR |
| 媒体文件 | 实时同步 | 永久 | R2/S3 |
| 配置文件 | Git 提交时 | 永久 | GitHub |
| Secrets | 变更时 | N/A | 1Password/Vault |

---

## 告警配置

### Cloudflare Notifications

1. Dashboard → Notifications
2. 配置以下告警：

| 告警类型 | 阈值 | 通知方式 |
|----------|------|----------|
| Worker 错误率 | > 1% | Email + Webhook |
| Worker CPU 时间 | > 10ms 平均 | Email |
| 流量异常 | ±50% 突变 | Email |
| SSL 证书过期 | 30 天内 | Email |

### 自定义告警

**使用 Webhook：**

```typescript
// worker/src/utils/alert.ts
export async function sendAlert(
  level: 'warning' | 'critical',
  message: string,
  context: Record<string, unknown>
): Promise<void> {
  const webhookUrl = env.ALERT_WEBHOOK_URL;
  if (!webhookUrl) return;

  await fetch(webhookUrl, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      level,
      message,
      context,
      timestamp: new Date().toISOString(),
      environment: env.ENVIRONMENT,
    }),
  });
}
```

**集成 PagerDuty/OpsGenie：**

```bash
# 设置 PagerDuty 集成
wrangler secret put PAGERDUTY_INTEGRATION_KEY
```

---

## 故障排查

### 常见问题

**1. Worker 超时（CPU 时间超过 50ms）**

原因：
- 数据库查询过慢
- 外部 API 调用超时
- 复杂计算

解决：
```typescript
// 添加查询超时
const controller = new AbortController();
const timeout = setTimeout(() => controller.abort(), 5000);

try {
  const response = await fetch(url, { signal: controller.signal });
} finally {
  clearTimeout(timeout);
}
```

**2. KV 缓存未命中率高**

检查：
```bash
# 查看 KV 统计
wrangler kv:key list --namespace-id=<id> | wc -l
```

解决：
- 增加缓存 TTL
- 检查缓存键策略
- 预热常用缓存

**3. 数据库连接问题**

检查：
```bash
# 测试连接
curl -i "https://xxx.supabase.co/rest/v1/" \
  -H "apikey: your-anon-key"
```

解决：
- 检查 Supabase 状态页
- 验证 API key 是否正确
- 检查 RLS 策略

### 调试工具

**本地调试：**

```bash
# 使用本地 Supabase
supabase start
wrangler dev --local

# 查看详细日志
LOG_LEVEL=debug wrangler dev
```

**远程调试：**

```bash
# 实时日志
wrangler tail --env production --format pretty

# 特定请求追踪
wrangler tail --env production --search "requestId=abc123"
```

### 性能分析

**识别慢查询：**

```sql
-- Supabase Dashboard → SQL Editor
SELECT 
  query,
  calls,
  mean_time,
  total_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 20;
```

**Worker 性能分析：**

```typescript
// 在代码中添加计时
const start = Date.now();
// ... 操作
console.log(`Operation took ${Date.now() - start}ms`);
```

---

## 维护清单

### 每日检查

- [ ] 检查错误日志
- [ ] 检查响应时间趋势
- [ ] 检查磁盘/存储使用

### 每周检查

- [ ] 审核安全日志
- [ ] 检查备份完整性
- [ ] 更新依赖（安全补丁）

### 每月检查

- [ ] 性能基准测试
- [ ] 成本分析
- [ ] 容量规划
- [ ] 灾难恢复演练

### 版本更新流程

1. 在 staging 环境测试
2. 检查数据库迁移
3. 更新环境变量（如需要）
4. 部署到生产
5. 监控 15 分钟
6. 确认或回滚
